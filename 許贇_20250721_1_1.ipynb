{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495541ac-7dd8-4093-8681-f834f5d36d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "984bb038-734b-46ae-b5be-d05390f9576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48097 entries, 0 to 48096\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       48097 non-null  float64\n",
      " 1   1       48097 non-null  float64\n",
      " 2   2       48097 non-null  float64\n",
      " 3   3       48097 non-null  float64\n",
      " 4   4       48097 non-null  float64\n",
      " 5   label   48097 non-null  int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "190e271d-0aa6-447a-bb6a-2893296bef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ取得\n",
    "Data = pd.read_csv(r'C:\\Users\\0208071\\Downloads\\_ABEJA_dataset_interview+.csv')\n",
    "# データセット情報確認（Null存在かどうかなど）\n",
    "Data.info()\n",
    "# 相関性確認。強い相関を持つ説明変数のどちらか除外する\n",
    "Data.corr()\n",
    "# 基本統計量など確認し、データ性質を把握する\n",
    "Info = []\n",
    "for i in range(5):\n",
    "    for j in range(8):\n",
    "      Info += [[i,j] + list(Data.loc[Data.label==j,Data.columns[i]].describe())]\n",
    "Info = pd.DataFrame(Info,columns=['ColNum','label','count','mean','std','min','25%','50%','75%','max'])\n",
    "# 今回のデータでは強い相関性確認されなかったため、除外なしでよい！\n",
    "### ↑精度向上施策Ⅰ：相関性確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de81bd7f-f02d-4d6a-8f4d-b2c906632f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量\n",
    "X = np.array(Data[Data.columns[0:5]])\n",
    "# ラベル\n",
    "y = np.array(Data[['label']]).reshape(-1, 1)\n",
    "# 訓練データとテストデータに分割(訓練8:テスト2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 特徴量の標準化\n",
    "# 訓練データの標準化時、テストデータをつかってはならない\n",
    "### ↑精度向上施策Ⅱ：特徴量ごとに平均・標準偏差を使って標準化せずに、特徴量行列に平均ベクトル・共分散行列を使って、標準化する\n",
    "### 相関性が低いが、相関性なしでないことを注意！\n",
    "### 今回実施なし\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "# ラベルをワンホットエンコーディング\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_onehot = encoder.fit_transform(y_train)\n",
    "y_test_onehot = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1f8bc3d-3407-4226-b069-442d2da5f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # 入力レイヤー\n",
    "    Dense(256, activation='leaky_relu'), ### 精度向上施策Ⅲ：中間層数・クラス数・活性化関数を調整\n",
    "    Dense(64, activation='leaky_relu'),\n",
    "    Dense(y_train_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "# モデルのコンパイル\n",
    "model.compile(optimizer='adam', ### 精度向上施策Ⅳ：最適化関数種類・ロス関数種類を調整\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08e4f833-e5e3-4779-8f95-9d8b0b21e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7204 - loss: 0.8377\n",
      "Epoch 2/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.5630\n",
      "Epoch 3/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.5375\n",
      "Epoch 4/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8118 - loss: 0.5232\n",
      "Epoch 5/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8179 - loss: 0.5103\n",
      "Epoch 6/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.5131\n",
      "Epoch 7/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.5049\n",
      "Epoch 8/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8204 - loss: 0.4953\n",
      "Epoch 9/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.4921\n",
      "Epoch 10/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.4978\n",
      "Epoch 11/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8195 - loss: 0.4966\n",
      "Epoch 12/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8201 - loss: 0.4926\n",
      "Epoch 13/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8230 - loss: 0.4846\n",
      "Epoch 14/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.4841\n",
      "Epoch 15/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8261 - loss: 0.4828\n",
      "Epoch 16/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8258 - loss: 0.4827\n",
      "Epoch 17/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8273 - loss: 0.4779\n",
      "Epoch 18/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8278 - loss: 0.4770\n",
      "Epoch 19/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.4785\n",
      "Epoch 20/20\n",
      "\u001b[1m1203/1203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "# モデルの学習\n",
    "history = model.fit(X_train, y_train_onehot, epochs=20, batch_size=32, verbose=1)\n",
    "### 精度向上施策Ⅴ：訓練回数（epochs）・バッチサイズを調整\n",
    "### 今回精度が安定的収束したため、訓練回数をこれ以上増やしても向上効果が出ない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f8b98f7-4bdc-4ea1-876b-9ecb443ef90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "テストデータの精度: 0.8255717158317566\n"
     ]
    }
   ],
   "source": [
    "# 評価\n",
    "### 評価方法には、一般的に　⓵ROC曲線とAUC　⓶F1スコアという総合的な評価基準があげられる\n",
    "### 分析目的によって、再現率に偏重したり、適合率に偏重したりすることはよくあるが、それらは根本的にモデル精度を向上することができない\n",
    "### 個人的に、もっともシンプルの正解率を重視する。正解率が安定すれば、モデル精度も安定するのである\n",
    "### モデル構築時に精度が高く、そのあと低下していくことは、よく発生する。安定しないモデルは信頼を失ってしまうことに！\n",
    "loss, accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "print(f\"テストデータの精度: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
